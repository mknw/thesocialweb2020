{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web\n",
    "\n",
    "## 2015-2016 Master Information Sciences\n",
    "\n",
    "* Instructors: Davide Ceolin, Dayana Spagnuelo\n",
    "* Lab Assistants: Michael Accetto, Sarthak Gupta, Ayesha Noorain \n",
    "* Exercises for Hands-on session 4\n",
    "* 5 March 2020 11:00 - 12:45\n",
    "* NU-5B-21, NU-6A-04, NU-6B-20, NU-6C-39, NU-6C-40   \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packages:\n",
    "* feedparser, praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in /home/ironfist/.local/lib/python3.7/site-packages (5.2.1)\n",
      "Requirement already satisfied: praw in /home/ironfist/.local/lib/python3.7/site-packages (6.5.1)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.0.1 in /home/ironfist/.local/lib/python3.7/site-packages (from praw) (1.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/ironfist/.local/lib/python3.7/site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied: update-checker>=0.16 in /home/ironfist/.local/lib/python3.7/site-packages (from praw) (0.16)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/ironfist/.local/lib/python3.7/site-packages (from prawcore<2.0,>=1.0.1->praw) (2.23.0)\n",
      "Requirement already satisfied: six in /home/ironfist/.local/lib/python3.7/site-packages (from websocket-client>=0.54.0->praw) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ironfist/.local/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ironfist/.local/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ironfist/.local/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ironfist/.local/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install feedparser\n",
    "!{sys.executable} -m pip install praw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For Exercises 1-3 you will need to save the script recommendations.py (from Programming Collaborative Intelligence) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from math import sqrt\n",
    "# A dictionary of movie critics and their ratings of a small set of movies\n",
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0,\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0,\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Toby': {'Snakes on a Plane': 4.5, 'You, Me and Dupree': 1.0,\n",
    "             'Superman Returns': 4.0},\n",
    "}\n",
    "\n",
    "\n",
    "def sim_distance(prefs, p1, p2):\n",
    "    '''\n",
    "    Returns a distance-based similarity score for person1 and person2.\n",
    "    '''\n",
    "\n",
    "    # Get the list of shared_items\n",
    "    si = {}\n",
    "    for item in prefs[p1]:\n",
    "        if item in prefs[p2]:\n",
    "            si[item] = 1\n",
    "    # If they have no ratings in common, return 0\n",
    "    if len(si) == 0:\n",
    "        return 0\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[p1][item] - prefs[p2][item], 2) for item in\n",
    "                         prefs[p1] if item in prefs[p2]])\n",
    "    return 1 / (1 + sum_of_squares)\n",
    "\n",
    "\n",
    "def sim_pearson(prefs, p1, p2):\n",
    "    '''\n",
    "    Returns the Pearson correlation coefficient for p1 and p2.\n",
    "    '''\n",
    "\n",
    "    # Get the list of mutually rated items\n",
    "    si = {}\n",
    "    for item in prefs[p1]:\n",
    "        if item in prefs[p2]:\n",
    "            si[item] = 1\n",
    "    # If they are no ratings in common, return 0\n",
    "    if len(si) == 0:\n",
    "        return 0\n",
    "    # Sum calculations\n",
    "    n = len(si)\n",
    "    # Sums of all the preferences\n",
    "    sum1 = sum([prefs[p1][it] for it in si])\n",
    "    sum2 = sum([prefs[p2][it] for it in si])\n",
    "    # Sums of the squares\n",
    "    sum1Sq = sum([pow(prefs[p1][it], 2) for it in si])\n",
    "    sum2Sq = sum([pow(prefs[p2][it], 2) for it in si])\n",
    "    # Sum of the products\n",
    "    pSum = sum([prefs[p1][it] * prefs[p2][it] for it in si])\n",
    "    # Calculate r (Pearson score)\n",
    "    num = pSum - sum1 * sum2 / n\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n) * (sum2Sq - pow(sum2, 2) / n))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    r = num / den\n",
    "    return r\n",
    "\n",
    "\n",
    "def topMatches(\n",
    "    prefs,\n",
    "    person,\n",
    "    n=5,\n",
    "    similarity=sim_pearson,\n",
    "):\n",
    "    '''\n",
    "    Returns the best matches for person from the prefs dictionary. \n",
    "    Number of results and similarity function are optional params.\n",
    "    '''\n",
    "\n",
    "    scores = [(similarity(prefs, person, other), other) for other in prefs\n",
    "              if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]\n",
    "\n",
    "\n",
    "def getRecommendations(prefs, person, similarity=sim_pearson):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "    # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(prefs, person, other)\n",
    "    # Ignore scores of zero or lower\n",
    "        if sim <= 0: \n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                    totals.setdefault(item, 0)\n",
    "                    # The final score is calculated by multiplying each item by the\n",
    "                    #   similarity and adding these products together\n",
    "                    totals[item] += prefs[other][item] * sim\n",
    "                    # Sum of similarities\n",
    "                    simSums.setdefault(item, 0)\n",
    "                    simSums[item] += sim\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item) for (item, total) in\n",
    "                totals.items()]\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings\n",
    "\n",
    "\n",
    "def transformPrefs(prefs):\n",
    "    '''\n",
    "    Transform the recommendations into a mapping where persons are described\n",
    "    with interest scores for a given title e.g. {title: person} instead of\n",
    "    {person: title}.\n",
    "    '''\n",
    "\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1: Finding Similar Users**\n",
    "\n",
    "In recommendations.py you see two different similarity metrics: Euclidean distance and the Pearson correlation. If you've done an Information Retrieval course, you've probably heard of these. If not, look them up.\n",
    "\n",
    "To find similar users in your little movie data set, you can fire up the following commands in your python interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14814814814814814"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import recommendations # make sure recommendations.py is in the directory you're working in now\n",
    "\n",
    "# get the distance between 'Lisa Rose' and 'Gene Seymour'\n",
    "recommendations.sim_distance(recommendations.critics,'Lisa Rose','Gene Seymour') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with other names so you can see who is closer or further.\n",
    "\n",
    "A slightly more sophisticated distance measure is the Pearson correlation. You can find the distance between 'Lisa Rose' and 'Gene Seymour' through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39605901719066977"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.sim_pearson(recommendations.critics,'Lisa Rose','Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also rank people according to how close they are. For this you have the topMatches function in recommendations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9912407071619299, 'Lisa Rose'),\n",
       " (0.9244734516419049, 'Mick LaSalle'),\n",
       " (0.8934051474415647, 'Claudia Puig')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.topMatches(recommendations.critics,'Toby',n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: Create a topMatches function that uses the Euclidean distance. Try it with other names and see if you find differences between the two measures, do you get different rankings with Euclidean?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2: Recommending Items**\n",
    "\n",
    "Finding similar persons is interesting, but of course you're more interested in finding interesting movies for a user. This is what the getRecommendations function does. For example, get recommendations for 'Toby' you can call: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.5002478401415877, 'The Night Listener'),\n",
       " (2.7561242939959363, 'Lady in the Water'),\n",
       " (2.461988486074374, 'Just My Luck')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.getRecommendations(recommendations.critics,'Toby')\n",
    "recommendations.getRecommendations(recommendations.critics,'Toby', similarity=recommendations.sim_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output does not only consist of a movie title, but also a guess at what the user's rating for each movie would be.\n",
    "\n",
    "*****************************************************\n",
    "#### Task: Can you also find out how to give information on how the recommendation is built up. For example about the 'closest' person that also watched this movie?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 3: In Exercise 2, you have been building recommendations based on similar users, but you could of course also build recommendations based on similar items. In this exercise you will do this.** \n",
    "\n",
    "The function is essentially the same, but you need to transfer your data, from:\n",
    "\n",
    "<code>{'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5}}</code>\n",
    "\n",
    "to\n",
    "\n",
    "<code>{'Lady in the Water': {'Lisa Rose': 2.5,'Gene Seymour': 3.0},\n",
    "'Snakes on a Plane': {'Lisa Rose': 3.5,'Gene Seymour': 3.5}}</code>\n",
    "\n",
    "This is what the transformPrefs function does. \n",
    "\n",
    "You can now create a dictionary for movies with their scores assigned by different people by invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=recommendations.transformPrefs(recommendations.critics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find similar items for a particular movie like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6579516949597695, 'You, Me and Dupree'),\n",
       " (0.4879500364742689, 'Lady in the Water'),\n",
       " (0.11180339887498941, 'Snakes on a Plane'),\n",
       " (-0.1798471947990544, 'The Night Listener'),\n",
       " (-0.42289003161103106, 'Just My Luck')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.topMatches(movies,'Superman Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find people who may like a particular movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.0, 'Michael Phillips'), (3.0, 'Jack Matthews')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.getRecommendations(movies,'Just My Luck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: Try to follow exactly what is going on in the last call. Notice that Michael and Jack did not rate 'Just my Luck'. How is their rating for it built up?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4: Building a Reddit Recommender (adapted from Programming Collective Intelligence by Toby Segaran)**\n",
    "\n",
    "Save the following code as redditrec.py after you replace the '???' in the user_agent string with your name (or any unique string).\n",
    "\n",
    "NOTE: install praw v. 3.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import praw\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "r = praw.Reddit(user_agent='android:com.example.myredditapp:v1.2.3 (by u/sg_ironfist)', client_id='vGNoMhBTUILWCQ',\n",
    "                      client_secret='2Yj2aLeMmi54Pfi-iG0rQip3yDQ',\n",
    "                      redirect_url='https://www.reddit.com/prefs/apps/'\n",
    "                                   'authorize_callback')\n",
    "\n",
    "def initializeUserDict(subreddit, count=10):\n",
    "  user_dict={}\n",
    "  # get the top count' popular posts\n",
    "  for p1 in r.subreddit(subreddit).top(limit=count):\n",
    "    # find all users who commented in this\n",
    "    flat_comments = praw.helpers.flatten_tree(p1.comments)\n",
    "    for p2 in flat_comments:\n",
    "        try:\n",
    "            user=p2.author.name\n",
    "            user_dict[user]={}\n",
    "        except AttributeError:\n",
    "            pass\n",
    "  return user_dict\n",
    "\n",
    "def fillItems(user_dict, count=100):\n",
    "  all_items={}\n",
    "  # Find links posted by all users\n",
    "  for user in user_dict:\n",
    "      # print user\n",
    "      posts = r.redditor(user).comments(limit = count)\n",
    "      for post in posts:\n",
    "          subreddit = post.subreddit\n",
    "          # print subreddit.display_name\n",
    "          if subreddit.display_name in user_dict[user]:\n",
    "              user_dict[user][subreddit.display_name] += 1.0\n",
    "          else:\n",
    "              user_dict[user][subreddit.display_name] = 1.0\n",
    "          all_items[subreddit.display_name]=1\n",
    "  \n",
    "  # Fill in missing items with 0\n",
    "  for ratings in user_dict.values():\n",
    "      for item in all_items:\n",
    "          if item not in ratings:\n",
    "              ratings[item]=0.0\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of popular recent posts about programming from the programming subreddit (https://www.reddit.com/r/programming) by invoking the code below.  Don't forget to replace the '???' in the user_agent string with your name (or any unique string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Can anyone tell me where this is? A friend send this and said that it was in one of the VU buildings.\n",
      "\n",
      " * I'm quite nervous about finding accommodation.\n",
      "\n",
      " * Psychology Selection Test\n",
      "\n",
      " * Studying abroad at VU and looking for suggestions on classes to take!\n",
      "\n",
      " * Any success with letting the vu search for housing for you?\n",
      "\n",
      " * About the Master on International crimes, conflict and criminology.\n",
      "\n",
      " * Math bachelor\n",
      "\n",
      " * Spots to study\n"
     ]
    }
   ],
   "source": [
    "r = praw.Reddit(client_id='vGNoMhBTUILWCQ',client_secret='2Yj2aLeMmi54Pfi-iG0rQip3yDQ',user_agent='android:com.example.myredditapp:v1.2.3 (by u/sg_ironfist)')\n",
    "\n",
    "subreddit = r.subreddit(\"programming\")\n",
    "for post in r.subreddit('VUAmsterdam').top(limit=10):\n",
    "    print(end='\\n * ')\n",
    "    print(post.title)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here a list of other subreddits you can explore with this code: https://www.reddit.com/reddits/\n",
    "\n",
    "To automatically create a data set of reddit users similar to the movie watchers you can invoke the initializeUserDict function in redditrec.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'praw' has no attribute 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2dd6b741855b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredditrec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mredditrec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mredusers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializeUserDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'programming'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# or for any other subreddit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/socialweb/socialEnv/redditrec.py\u001b[0m in \u001b[0;36minitializeUserDict\u001b[0;34m(subreddit, count)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# find all users who commented in this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mflat_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_comments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'praw' has no attribute 'helpers'"
     ]
    }
   ],
   "source": [
    "import redditrec\n",
    "from redditrec import *\n",
    "redusers=initializeUserDict('programming') # or for any other subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initializeUserDict has only created the user keys. We of course also want to know what subreddits they posted comments on. You can pull those in through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'redusers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3aaefd4e869a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfillItems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredusers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'redusers' is not defined"
     ]
    }
   ],
   "source": [
    "fillItems(redusers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script may take a few minutes to collect all the data. Use this time to review what is going on in the code. Notice that users don't give ratings to subreddits, instead we are counting how many comments they posted in each subreddit. \n",
    "\n",
    "To recommend a similar user, we can use our first script (recommendations.py) again.\n",
    "\n",
    "First choose a random user for whom you're going to find neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'redusers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0c065cb5ca4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredusers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredusers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print the username\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopMatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredusers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# from all redditors, get the most similar to user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'redusers' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "user=redusers.keys()[random.randint(0,len(redusers)-1)] \n",
    "print (user) # print the username \n",
    "recommendations.topMatches(redusers,user) # from all redditors, get the most similar to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task 4: Recommend subreddits for a user based on what subreddits similar users have commented in. Recommend posts for a user based on posts they have commented on. \n",
    "*****************************************************\n",
    "\n",
    "*****************************************************\n",
    "#### Task 5: Reuse the data and scripts you have created in hands-on session 3 to build a recommender for your Facebook friends. Can you get page recommendations from your friends? What other things would be interesting to recommend?\n",
    "*****************************************************\n",
    "\n",
    "For those who are considering using recommendations further:\n",
    "So far, we have been basing recommendations on the full data set, obviously this is a bad idea if you have a big data set. You can prune your dataset by first computing similar items. The code to do so is already in recommendations.py and you can work with it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'recommendations' has no attribute 'calculateSimilarItems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-abfeb5831a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitemsim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateSimilarItems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRecommendedItems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitemsim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Toby'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'recommendations' has no attribute 'calculateSimilarItems'"
     ]
    }
   ],
   "source": [
    "itemsim=recommendations.calculateSimilarItems(recommendations.critics)\n",
    "recommendations.getRecommendedItems(recommendations.critics,itemsim,'Toby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the code from the Computational Intelligence book on “Building the Item Comparison Dataset” (pages 23-25), https://github.com/VU-Amsterdam-Web-Media-Group/TheSocialWeb2016/blob/master/lib/Handson4-Building-Item-Comparison-Dataset.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
