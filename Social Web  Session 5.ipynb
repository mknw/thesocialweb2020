{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web\n",
    "\n",
    "## 2019-2020 Master Information Sciences\n",
    "\n",
    "* Instructors: Davide Ceolin, Dayana Spagnuelo\n",
    "* Teachers Assistants: Michael Accetto, Sarthak Gupta, Ayesha Noorain\n",
    "* Exercises for Hands-on session 5\n",
    "* 12 March 11:00 - 12:45\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Software: \n",
    "* Python 3 \n",
    "* Python packages: twitter\n",
    "\n",
    "\n",
    "In this session you are going to learn how to browse user profiles information.\n",
    "There are some scripts present below which will help you solve the exercises. \n",
    "Make sure to run all the scripts before you start the exercises.\n",
    "\n",
    "\n",
    "First, we set up the Twitter API permissions.\n",
    "You need to fill in the empty strings with your credentials. You will need it for all the exercises.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "\tCONSUMER_KEY = ''\n",
    "\tCONSUMER_SECRET = ''\n",
    "\tOAUTH_TOKEN = ''\n",
    "\tOAUTH_TOKEN_SECRET = ''\n",
    "\tauth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "\tCONSUMER_KEY, CONSUMER_SECRET)\n",
    "\ttwitter_api = twitter.Twitter(auth=auth)\n",
    "\treturn twitter_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweet_content(statuses): \n",
    "\tif len(statuses) == 0: \n",
    "\t\tprint (\"No statuses to analyze\")\n",
    "        \n",
    "\t\treturn\n",
    "\t# A nested helper function for computing lexical diversity\n",
    "\tdef lexical_diversity(tokens): \n",
    "\t\treturn 1.0*len(set(tokens))/len(tokens)\n",
    "\t# A nested helper function for computing the average number of words per tweet\n",
    "\tdef average_words(statuses): \n",
    "\t\ttotal_words = sum([ len(s.split()) for s in statuses ])\n",
    "\t\treturn 1.0*total_words/len(statuses) \n",
    "\tstatus_texts = [ status['text'] for status in statuses ] \n",
    "\tscreen_names, hashtags, urls, media, _ = extract_tweet_entities(statuses)\n",
    "\t# Compute a collection of all words from all tweets\n",
    "\twords = [ w \n",
    "\t\tfor t in status_texts \n",
    "\t\t\tfor w in t.split() ] \n",
    "\tprint (\"Lexical diversity (words):\"), lexical_diversity(words) \n",
    "\tprint (\"Lexical diversity (screen names):\"),lexical_diversity(screen_names) \n",
    "\tprint (\"Lexical diversity (hashtags):\"),lexical_diversity(hashtags) \n",
    "\tprint (\"Averge words per tweet:\"),average_words(status_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweet_entities(statuses):\n",
    "# See https://dev.twitter.com/docs/tweet-entities for more details on tweet\n",
    "# entities\n",
    "    if len(statuses) == 0:\n",
    "        return [], [], [], [], []\n",
    "    screen_names = [ user_mention['screen_name']\n",
    "        for status in statuses\n",
    "            for user_mention in status['entities']['user_mentions'] ]\n",
    "    hashtags = [ hashtag['text']\n",
    "        for status in statuses\n",
    "            for hashtag in status['entities']['hashtags'] ]\n",
    "    urls = [ url['expanded_url']\n",
    "        for status in statuses\n",
    "            for url in status['entities']['urls'] ]\n",
    "    symbols = [ symbol['text']\n",
    "        for status in statuses\n",
    "            for symbol in status['entities']['symbols'] ]\n",
    "    # In some circumstances (such as search results), the media entity\n",
    "    # may not appear\n",
    "    for status in statuses:\n",
    "        if status['entities'] in status['media']:\n",
    "            media = [ media['url']\n",
    "                for status in statuses\n",
    "                for media in status['entities']['media'] ]\n",
    "        else:\n",
    "            media = []\n",
    "    return screen_names, hashtags, urls, media, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sys import maxsize\n",
    "from functools import partial \n",
    "\n",
    "def get_friends_followers_ids(screen_name=None, user_id=None, friends_limit=maxsize, followers_limit=maxsize):# Must have either screen_name or user_id (logical xor)\n",
    "    \n",
    "    twitter_api = oauth_login()\n",
    "    \n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_names or user_ids, but not both\"\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/friends/ids and https://dev.twitter.com/docs/api/1.1/get/followers/ids for details on API parameters\n",
    "\n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, count=5000)\n",
    "\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids,count=5000) \n",
    "    \n",
    "    friends_ids, followers_ids = [], [] \n",
    "\n",
    "    for twitter_api_func, limit, ids,label in [[get_friends_ids, friends_limit, friends_ids, \"friends\"],[get_followers_ids, followers_limit, followers_ids, \"followers\"]]:\n",
    "         if limit == 0: continue \n",
    "         cursor = -1 \n",
    "         while cursor != 0:\n",
    "# Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id \n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor) \n",
    "            if response is not None: \n",
    "                ids += response['ids'] \n",
    "                cursor = response['next_cursor'] \n",
    "            print (sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids), label, (user_id or screen_name)))\n",
    "\t\t# XXX: You may want to store data during each iteration to provide an an additional layer\n",
    "\t\t# of protection from exceptional circumstances\n",
    "            if len(ids) >= limit or response is None: \n",
    "                break\n",
    "\t# Do something useful with the IDs, like store them to disk...\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(screen_names=None, user_ids=None):# Must have either screen_name or user_id (logical xor)\n",
    "\ttwitter_api = oauth_login()\n",
    "\tassert (screen_names != None) != (user_ids != None), \\\n",
    "\t\"Must have screen_names or user_ids, but not both\"\n",
    "\titems_to_info = {}\n",
    "\titems = screen_names or user_ids\n",
    "\twhile len(items) > 0: # Process 100 items at a time per the API specifications for /users/lookup\n",
    "\t\titems_str = ','.join([str(item) for item in items[:100]])\n",
    "\t\titems = items[100:]\n",
    "\t\tif screen_names:\n",
    "\t\t\tresponse = make_twitter_request(twitter_api.users.lookup,screen_name=items_str)\n",
    "\t\telse: # user_ids\n",
    "\t\t\tresponse = make_twitter_request(twitter_api.users.lookup,user_id=items_str)\n",
    "\t\tprint (response)\n",
    "\t\tfor user_info in response:\n",
    "\t\t\tif screen_names:\n",
    "\t\t\t\titems_to_info[user_info['screen_name']] = user_info\n",
    "\t\t\telse: # user_ids\n",
    "\t\t\t\titems_to_info[user_info['id']] = user_info\n",
    "\tprint (items_to_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def harvest_user_timeline(screen_name=None, user_id=None, max_results=1000):\n",
    "\ttwitter_api = oauth_login()\n",
    "\tassert (screen_name != None) != (user_id != None), \\\n",
    "\t\"Must have screen_name or user_id, but not both\"\n",
    "\tkw = { # Keyword args for the Twitter API call\n",
    "\t\t'count': 200,\n",
    "\t\t'trim_user': 'true',\n",
    "\t\t'include_rts' : 'true',\n",
    "\t\t'since_id' : 1\n",
    "\t\t}\n",
    "\n",
    "\tif screen_name:\n",
    "\t\tkw['screen_name'] = screen_name\n",
    "\telse:\n",
    "\t\tkw['user_id'] = user_id\n",
    "\t\n",
    "\tmax_pages = 16\n",
    "\tresults = []\n",
    "\t\n",
    "\ttweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "\tif tweets is None: # 401 (Not Authorized) - Need to bail out on loop entry\n",
    "\t\ttweets = []\n",
    "\tresults += tweets\n",
    "\t\n",
    "\tprint (sys.stderr, 'Fetched %i tweets' % len(tweets))\n",
    "\t\n",
    "\tpage_num = 1\n",
    "\t\n",
    "\t# Many Twitter accounts have fewer than 200 tweets so you don't want to enter\n",
    "\t# the loop and waste a precious request if max_results = 200.\n",
    "\t# Note: Analogous optimizations could be applied inside the loop to try and\n",
    "\t# save requests. e.g. Don't make a third request if you have 287 tweets out of\n",
    "\t# a possible 400 tweets after your second request. Twitter does do some\n",
    "\t# post-filtering on censored and deleted tweets out of batches of 'count', though,\n",
    "\t# so you can't strictly check for the number of results being 200. You might get\n",
    "\t# back 198, for example, and still have many more tweets to go. If you have the\n",
    "\t# total number of tweets for an account (by GET /users/lookup/), then you could\n",
    "\t# simply use this value as a guide.\n",
    "\t\n",
    "\tif max_results == kw['count']:\n",
    "\t\tpage_num = max_pages # Prevent loop entry\n",
    "\twhile page_num < max_pages and len(tweets) > 0 and len(results) < max_results:\n",
    "\t\n",
    "\t# Necessary for traversing the timeline in Twitter's v1.1 API:\n",
    "\t# get the next query's max-id parameter to pass in.\n",
    "\t# See https://dev.twitter.com/docs/working-with-timelines.\n",
    "\t\tkw['max_id'] = min([ tweet['id'] for tweet in tweets]) - 1\n",
    "\t\ttweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "\t\tresults += tweets\n",
    "\t\tprint (sys.stderr, 'Fetched %i tweets' % (len(tweets),))\n",
    "\t\tpage_num += 1\n",
    "\tprint (sys.stderr, 'Done fetching tweets')\n",
    "\treturn results[:max_results]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib.request  import URLError\n",
    "from http.client  import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw):\n",
    "\t# A nested helper function that handles common HTTPErrors. Return an updated\n",
    "\t# value for wait_period if the problem is a 500 level error. Block until the\n",
    "\t# rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "\t# for 401 and 404 errors, which requires special handling by the caller.\n",
    "\tdef handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "\t\tif wait_period > 3600: # Seconds\n",
    "\t\t\tprint >> (sys.stderr, 'Too many retries. Quitting.')\n",
    "\t\t\traise e\n",
    "\t\t# See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "\t\t\tif e.e.code == 401:\n",
    "\t\t\t\tprint >> (sys.stderr, 'Encountered 401 Error (Not Authorized)')\n",
    "\t\t\t\treturn None\n",
    "\t\t\telif e.e.code == 404:\n",
    "\t\t\t\tprint >> (sys.stderr, 'Encountered 404 Error (Not Found)')\n",
    "\t\t\t\treturn None\n",
    "\t\t\telif e.e.code == 429:\n",
    "\t\t\t\tprint >> (sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)')\n",
    "\t\t\t\tif sleep_when_rate_limited:\n",
    "\t\t\t\t\tprint >> (sys.stderr, \"Retrying in 15 minutes...ZzZ...\")\n",
    "\t\t\t\t\tsys.stderr.flush()\n",
    "\t\t\t\t\ttime.sleep(60*15 + 5)\n",
    "\t\t\t\t\tprint >> (sys.stderr, '...ZzZ...Awake now and trying again.')\n",
    "\t\t\t\t\treturn 2\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\traise e # Caller must handle the rate limiting issue\n",
    "\t\t\telif e.e.code in (500, 502, 503, 504):\n",
    "\t\t\t\tprint >> (sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
    "\t\t\t\t\t(e.e.code, wait_period))\n",
    "\t\t\t\ttime.sleep(wait_period)\n",
    "\t\t\t\twait_period *= 1.5\n",
    "\t\t\t\treturn wait_period\n",
    "\t\t\telse:\n",
    "\t\t\t\traise e\n",
    "\t\t# End of nested helper function\n",
    "\twait_period = 2\n",
    "\terror_count = 0\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\treturn twitter_api_func(*args, **kw)\n",
    "\t\texcept twitter.api.TwitterHTTPErro as e:\n",
    "\t\t\terror_count = 0\n",
    "\t\t\twait_period = handle_twitter_http_error(e, wait_period)\n",
    "\t\t\tif wait_period is None:\n",
    "\t\t\t\treturn\n",
    "\t\texcept URLError as e:\n",
    "\t\t\terror_count += 1\n",
    "\t\t\tprint >> sys.stderr, \"URLError encountered. Continuing.\"\n",
    "\t\t\tif error_count > max_errors:\n",
    "\t\t\t\tprint >> (sys.stderr, \"Too many consecutive errors...bailing out.\")\n",
    "\t\t\t\traise\n",
    "\t\texcept BadStatusLine as e:\n",
    "\t\t\terror_count += 1\n",
    "\t\t\tprint >> (sys.stderr, \"BadStatusLine encountered. Continuing.\")\n",
    "\t\t\tif error_count > max_errors:\n",
    "\t\t\t\tprint >> (sys.stderr, \"Too many consecutive errors...bailing out.\")\n",
    "\t\t\t\traise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids):\n",
    "\tfriends_ids, followers_ids = set(friends_ids), set(followers_ids) \n",
    "\tprint ('{0} is following {1}'.format(screen_name, len(friends_ids))) \n",
    "\tprint ('{0} is being followed by {1}'.format(screen_name, len(followers_ids)) )\n",
    "\tprint ('{0} of {1} are not following {2} back'.format( \n",
    "\t\tlen(friends_ids.difference(followers_ids)), \n",
    "\t\tlen(friends_ids),screen_name)) \n",
    "\tprint ('{0} of {1} are not being followed back by {2}'.format(\n",
    "\t\tlen(followers_ids.difference(friends_ids)), \n",
    "\t\tlen(followers_ids), screen_name)) \n",
    "\tprint ('{0} has {1} mutual friends'.format( \n",
    "\t\tscreen_name,len(friends_ids.intersection(followers_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_search(q, max_results=200, **kw):\n",
    "\ttwitter_api = oauth_login()\n",
    "\t# See https://dev.twitter.com/docs/api/1.1/get/search/tweets and\n",
    "\t# https://dev.twitter.com/docs/using-search for details on advanced\n",
    "\t# search criteria that may be useful for keyword arguments\n",
    "\t# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "\tsearch_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "\tstatuses = search_results['statuses']\n",
    "\t# Iterate through batches of results by following the cursor until we\n",
    "\t# reach the desired number of results, keeping in mind that OAuth users\n",
    "\t# can \"only\" make 180 search queries per 15-minute interval. See\n",
    "\t# https://dev.twitter.com/docs/rate-limiting/1.1/limits\n",
    "\t# for details. A reasonable number of results is ~1000, although\n",
    "\t# that number of results may not exist for all queries.\n",
    "\t# Enforce a reasonable limit\n",
    "\tmax_results = min(1000, max_results)\n",
    "\tfor _ in range(10): # 10*100 = 1000\n",
    "\t\ttry:\n",
    "\t\t\tnext_results = search_results['search_metadata']['next_results']\n",
    "\t\texcept KeyError as e: # No more results when next_results doesn't exist\n",
    "\t\t\tbreak\n",
    "\t# Create a dictionary from next_results, which has the following form:\n",
    "\t# ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "\t\tkwargs = dict([ kv.split('=')\n",
    "\t\t\tfor kv in next_results[1:].split(\"&\") ])\n",
    "\t\tsearch_results = twitter_api.search.tweets(**kwargs)\n",
    "\t\tstatuses += search_results['statuses']\n",
    "\t\tif len(statuses) > max_results:\n",
    "\t\t\tbreak\n",
    "\treturn statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 1:** Resolving user profile information (from example 9-17 in Mining the Social\n",
    "Web).\n",
    "\n",
    "Many APIs, such as GET friends/ids and GET followers/ids, return opaque ID values that\n",
    "need to be resolved to usernames or other profile information for meaningful analysis.\n",
    "Twitter provides a GET users/lookup API that can be used to resolve as many as 100 IDs or\n",
    "usernames at a time, and a simple pattern can be employed to iterate over larger batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can substitute the strings with others you like more\n",
    "get_user_profile(screen_names=[\"SocialWebMining\", \"ptwobrussell\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Getting all friends or followers for a user (from example 9-19 in Mining the\n",
    "Social Web).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can substitute the strings with others you are more interested in\n",
    "\n",
    "screen_name=\"SocialWebMining\"\n",
    "friends_ids, followers_ids = get_friends_followers_ids(screen_name=screen_name,friends_limit=10,followers_limit=10)\n",
    "\n",
    "print (friends_ids)\n",
    "print (followers_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Analyzing a user’s friends and followers (from example 9-20 in Mining the\n",
    "Social Web).\n",
    "\n",
    "After harvesting all of a user’s friends and followers, you can conduct some primitive\n",
    "analyses using only the ID values themselves with the help of setwise operations such as\n",
    "intersection and difference, as shown in the following exercise. Given two sets, the\n",
    "intersection of the sets returns the items that they have in common, whereas the\n",
    "difference between the sets “subtracts” the items in one set from the other, leaving\n",
    "behind the difference. Recall that intersection is a commutative operation, while\n",
    "difference is not commutative. \n",
    "\n",
    "In the context of analyzing friends and followers, the\n",
    "intersection of two sets can be interpreted as “mutual friends” or people you are\n",
    "following who are also following you back, while the difference of two sets can be\n",
    "interpreted as followers who you aren’t following back or people you are following who\n",
    "aren’t following you back, depending on the order of the operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"ptwobrussell\"\n",
    "friends_ids, followers_ids = get_friends_followers_ids(screen_name=screen_name)\n",
    "setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Harvesting a user’s tweets (from example 9-21 in Mining the Social Web).\n",
    "Timelines are a fundamental concept in the Twitter developer ecosystem, and Twitter\n",
    "provides a convenient API endpoint for the purpose of harvesting tweets by user through\n",
    "the concept of a “user timeline.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = harvest_user_timeline(screen_name=\"SocialWebMining\", max_results=200)\n",
    "print (tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Analyzing tweet content (from example 9-23 in Mining the Social Web). \n",
    "You will be using simple statistics, such as lexical diversity and average number of words per\n",
    "tweet, to gain elementary insight into what is being talked about as a first step in\n",
    "sizing up the nature of the language being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = 'CrossFit' \n",
    "search_results = twitter_search(q) \n",
    "analyze_tweet_content(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "TASK 1: Analyze all of the tweets that you (or another user you are interested in) have ever retweeted. Are you at all surprised about what you have retweeted or how your (or his/her) interests have evolved over time?\n",
    "*****************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*****************************************************\n",
    "TASK 2: Write a recipe to identify followers that you are not following back but perhaps should follow back based upon the content of their tweets. A few similarity measurements that may make suitable starting points were introduced in Section 3.3.3 on page 112 in the Mining the Social Web.\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
